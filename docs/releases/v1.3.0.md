# Release v1.3.0 - 2024-06-24

## Overview

This release introduces a major new feature: **GFPGAN Face Restoration**, which significantly enhances the quality of face crops. It also includes a fundamental redesign of the frame selection logic, moving to a powerful new **person-based selection system** that provides more diverse and relevant results.

## ðŸš€ New Features

- **Person-Based Frame Selection**: The core selection algorithm has been redesigned to be person-centric. Instead of selecting the best overall frames from a video, the system now identifies distinct people and selects a diverse set of high-quality images for each one. This provides more comprehensive and organized results, especially in videos with multiple people.
  - **Category-Based Diversity**: By default, the system selects a variety of poses (e.g., standing, sitting) and head angles (e.g., front, profile) for each person to ensure a diverse output. This can be configured via the `enable_pose_categories` and `enable_head_angle_categories` options.

- **GFPGAN Face Restoration**: Integrated **GFPGAN v1.4** to provide high-quality face restoration for all extracted face crops. This feature enhances facial details, corrects artifacts, and improves overall image clarity.
    - This is **disabled by default** to maintain performance.
    - Enable it with the `--face-restoration` flag or by setting `face_restoration_enabled: true` in your configuration file.
    - The restoration strength can be adjusted using `--face-restoration-strength` (from 0.0 to 1.0).

## ðŸ› ï¸ Improvements & Developer Experience

- **Extensible Model Management**: The model configuration system has been refactored for greater flexibility, simplifying the integration of new models like GFPGAN and ensuring a more maintainable architecture.
- **New `PersonSelector` Class**: The new person-based selection logic is encapsulated in `personfromvid/analysis/person_selector.py`, providing a clear, reusable component for this key functionality.
- **New `FaceRestorer` Class**: A dedicated `FaceRestorer` class in `personfromvid/models/face_restorer.py` encapsulates the logic for GFPGAN, following existing architectural patterns.
- **Expanded Configuration & CLI**: Added new configuration options and CLI flags to control the face restoration feature, allowing for easy experimentation and use.

## âš ï¸ Known Issues & Limitations

- **Naive Person Identification**: Person identification is based on a simple left-to-right indexing within each frame. When multiple people are detected, they are assigned sequential IDs (0, 1, 2, etc.) from left to right. This is a temporary implementation; true identity tracking across frames is planned for a future release.

## ðŸ“¦ Dependencies

- **Added `gfpgan>=1.3.8`**: This new dependency is required for the face restoration feature. The GFPGAN model (`GFPGANv1.4.pth`, ~348MB) will be downloaded automatically on first use.

## ðŸš¨ Upgrade Instructions

1.  **Upgrade Package**: To get the new features, upgrade the package using pip:
    ```bash
    pip install --upgrade personfromvid
    ```
2.  **New Selection Behavior**: The default selection logic has changed to prioritize person-based diversity. If you prefer the old behavior of selecting only the highest quality frames overall, you can set `enable_pose_categories: false` and `enable_head_angle_categories: false` in your configuration file.
3.  **Face Restoration is Off by Default**: To use the new face restoration feature, you must enable it via the `--face-restoration` CLI flag or by setting `face_restoration_enabled: true` in your configuration file.
4.  **Model Download**: The first time you run with face restoration enabled, the application will download the ~348MB GFPGAN model. Please ensure you have a stable internet connection.
5.  **Processing Time**: Be aware that enabling face restoration will significantly increase processing time for each face detected.